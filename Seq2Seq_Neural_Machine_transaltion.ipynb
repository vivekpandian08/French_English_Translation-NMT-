{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Neural_Machine_transaltion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y_CYNWmMufA",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhOH9T1tMS4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e8f41c9-8595-47fc-bbff-443b1fe8c526"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import io\n",
        "import numpy as np\n",
        "from unicodedata import normalize\n",
        "import keras, tensorflow\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtHkIlTLM2ML",
        "colab_type": "text"
      },
      "source": [
        "Reading data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnLdbP-bMtse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(file):\n",
        "    data = []\n",
        "    with io.open(file, 'r') as file:\n",
        "        for entry in file:\n",
        "            entry = entry.strip()\n",
        "            data.append(entry)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Extv5v91Mtva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_data('/content/bilingual_pairs.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91pv2AEZMt0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "0d15b0aa-ffbe-433f-b417-71e3b86aac56"
      },
      "source": [
        "data[90:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Come on.\\tViens !',\n",
              " 'Come on.\\tVenez !',\n",
              " 'Drop it!\\tLaisse tomber !',\n",
              " 'Drop it!\\tLaissez tomber !',\n",
              " 'Drop it!\\tLaisse-le tomber !',\n",
              " 'Drop it!\\tLaissez-le tomber !',\n",
              " 'Get out!\\tSortez\\u202f!',\n",
              " 'Get out!\\tSors !',\n",
              " 'Get out!\\tSortez !',\n",
              " 'Get out.\\tSors.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w6YoQ-VMt5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dd2b41d-4510-412f-8872-705ffe903c9f"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9AHwypgMt8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data[:140000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_zaCw4EOn3-",
        "colab_type": "text"
      },
      "source": [
        "Splitting our data into English and French sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcvSFoW2OpQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_english_french_sentences(data):\n",
        "    english_sentences = []\n",
        "    french_sentences = []\n",
        "    for data_point in data:\n",
        "        english_sentences.append(data_point.split(\"\\t\")[0])\n",
        "        french_sentences.append(data_point.split(\"\\t\")[1])\n",
        "    return english_sentences, french_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh8ctPO0Opxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_sentences, french_sentences = build_english_french_sentences(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieT-4bDQOp0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a8ef6db-f43c-4c22-bc36-870eb128d7d0"
      },
      "source": [
        "len(english_sentences),len(french_sentences)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140000, 140000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlgNafDiN39E",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Q9vHdKMuA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_sentences(sentence):\n",
        "    # prepare regex for char filtering\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    # prepare translation table for removing punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    cleaned_sent = normalize('NFD', sentence).encode('ascii', 'ignore')\n",
        "    cleaned_sent = cleaned_sent.decode('UTF-8')\n",
        "    cleaned_sent = cleaned_sent.split()\n",
        "    cleaned_sent = [word.lower() for word in cleaned_sent]\n",
        "    cleaned_sent = [word.translate(table) for word in cleaned_sent]\n",
        "    cleaned_sent = [re_print.sub('', w) for w in cleaned_sent]\n",
        "    cleaned_sent = [word for word in cleaned_sent if word.isalpha()]\n",
        "    return ' '.join(cleaned_sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVZ7MsSsN24A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_clean_english_french_sentences(english_sentences, french_sentences):\n",
        "    french_sentences_cleaned = []\n",
        "    english_sentences_cleaned = []\n",
        "    for sent in french_sentences:\n",
        "        french_sentences_cleaned.append(clean_sentences(sent))\n",
        "    for sent in english_sentences:\n",
        "        english_sentences_cleaned.append(clean_sentences(sent))\n",
        "    return english_sentences_cleaned, french_sentences_cleaned"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAFkspkaN27R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_sentences_cleaned, french_sentences_cleaned = build_clean_english_french_sentences(english_sentences, french_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MPMwnzPN3BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edc3da2c-4f28-47f9-ea19-9450b3b5c2dc"
      },
      "source": [
        "english_sentences_cleaned[4020]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'youre early'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaM82TF8N3Ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c0a6855-35f3-44c9-e8ee-d6f46a063dff"
      },
      "source": [
        "french_sentences_cleaned[4020]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vous etes matinal'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9f1RhRmPG0S",
        "colab_type": "text"
      },
      "source": [
        "Building our input and target variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBTuTwFGN3K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_data(english_sentences_cleaned, french_sentences_cleaned):\n",
        "    input_dataset = []\n",
        "    target_dataset = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "    \n",
        "    for french_sentence in french_sentences_cleaned:\n",
        "        input_datapoint = french_sentence\n",
        "        input_dataset.append(input_datapoint)\n",
        "        for char in input_datapoint:\n",
        "            input_characters.add(char)\n",
        "        \n",
        "    for english_sentence in english_sentences_cleaned:\n",
        "        target_datapoint = \"\\t\" + english_sentence + \"\\n\"\n",
        "        target_dataset.append(target_datapoint)\n",
        "        for char in target_datapoint:\n",
        "            target_characters.add(char)\n",
        "            \n",
        "    return input_dataset, target_dataset, sorted(list(input_characters)), sorted(list(target_characters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry3vsDwnN3OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dataset, target_dataset, input_characters, target_characters = build_data(english_sentences_cleaned,  french_sentences_cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIsqKKKiN3FU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_metadata(input_dataset, target_dataset, input_characters, target_characters):\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    max_encoder_seq_length = max([len(data_point) for data_point in input_dataset])\n",
        "    max_decoder_seq_length = max([len(data_point) for data_point in target_dataset])\n",
        "\n",
        "    print('Number of data points:', len(input_dataset))\n",
        "    print('Number of unique input tokens:', num_encoder_tokens)\n",
        "    print('Number of unique output tokens:', num_decoder_tokens)\n",
        "    print('Maximum sequence length for inputs:', max_encoder_seq_length)\n",
        "    print('Maximum sequence length for outputs:', max_decoder_seq_length)\n",
        "    \n",
        "    return num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPEi4q_MN2_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "facdeb14-66d4-4676-96a3-c48a09f68dcf"
      },
      "source": [
        "num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length = build_metadata(input_dataset,\n",
        "                                                                                                        target_dataset,\n",
        "                                                                                                        input_characters,\n",
        "                                                                                                        target_characters)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of data points: 140000\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 29\n",
            "Maximum sequence length for inputs: 117\n",
            "Maximum sequence length for outputs: 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC-R6izdRNcW",
        "colab_type": "text"
      },
      "source": [
        "Developing mappings for character to index :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqmVGkJLRPRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_indices(input_characters, target_characters):\n",
        "    input_char_to_idx = {}\n",
        "    input_idx_to_char = {}\n",
        "    target_char_to_idx = {}\n",
        "    target_idx_to_char = {}\n",
        "    \n",
        "    for i, char in enumerate(input_characters):\n",
        "        input_char_to_idx[char] = i\n",
        "        input_idx_to_char[i] = char\n",
        "    \n",
        "    for i, char in enumerate(target_characters):\n",
        "        target_char_to_idx[char] = i\n",
        "        target_idx_to_char[i] = char\n",
        "    \n",
        "    return input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char\n",
        "\n",
        "input_char_to_idx, input_idx_to_char, target_char_to_idx, target_idx_to_char = build_indices(input_characters,\n",
        "                                                                                             target_characters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb_eKAAbREIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fbd99f0d-4334-4f65-ded1-804d8354a74b"
      },
      "source": [
        "def build_data_structures(length_input_dataset, max_encoder_seq_length, max_decoder_seq_length, num_encoder_tokens, num_decoder_tokens):\n",
        "    encoder_input_data = np.zeros((length_input_dataset, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    decoder_input_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    decoder_target_data = np.zeros((length_input_dataset, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "    print(\"Dimensionality of encoder input data is : \", encoder_input_data.shape)\n",
        "    print(\"Dimensionality of decoder input data is : \", decoder_input_data.shape)\n",
        "    print(\"Dimensionality of decoder target data is : \", decoder_target_data.shape)\n",
        "    \n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = build_data_structures(len(input_dataset), \n",
        "                                                                                    max_encoder_seq_length, \n",
        "                                                                                    max_decoder_seq_length, \n",
        "                                                                                    num_encoder_tokens, \n",
        "                                                                                    num_decoder_tokens)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensionality of encoder input data is :  (140000, 117, 27)\n",
            "Dimensionality of decoder input data is :  (140000, 58, 29)\n",
            "Dimensionality of decoder target data is :  (140000, 58, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJzijR3FRxEh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H6617-0RELp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_data_to_data_structures(input_dataset, target_dataset, encoder_input_data, decoder_input_data, decoder_target_data):\n",
        "    for i, (input_data_point, target_data_point) in enumerate(zip(input_dataset, target_dataset)):\n",
        "        for t, char in enumerate(input_data_point):\n",
        "            encoder_input_data[i, t, input_char_to_idx[char]] = 1.\n",
        "        for t, char in enumerate(target_data_point):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t, target_char_to_idx[char]] = 1.\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_char_to_idx[char]] = 1.\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osojmhNDRESV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data, decoder_input_data, decoder_target_data = add_data_to_data_structures(input_dataset, \n",
        "                                                                                          target_dataset, \n",
        "                                                                                          encoder_input_data, \n",
        "                                                                                          decoder_input_data, \n",
        "                                                                                          decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj7VSkaxTFze",
        "colab_type": "text"
      },
      "source": [
        "Defining our model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h8Zj0wSREWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 512\n",
        "epochs = 100\n",
        "latent_dim = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU38Crn6TN3R",
        "colab_type": "text"
      },
      "source": [
        "Encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mEdI_3pRERB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUyyWkxqTSML",
        "colab_type": "text"
      },
      "source": [
        "Decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eckYmhfMuER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6qrpbUGTcqZ",
        "colab_type": "text"
      },
      "source": [
        "Building model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnmcqC1ATZoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
        "              outputs=decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH4VFMEUTZrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "856cf06e-99f5-46e0-f443-e78e2047bfe0"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 27)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 29)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 290816      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  292864      input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 29)     7453        lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 591,133\n",
            "Trainable params: 591,133\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WX-CFqNTsUG",
        "colab_type": "text"
      },
      "source": [
        "Model Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3zZMczWTZxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88bd6f3a-6782-451f-e6dc-f1a7391c52da"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 112000 samples, validate on 28000 samples\n",
            "Epoch 1/100\n",
            "112000/112000 [==============================] - 104s 931us/step - loss: 0.9429 - val_loss: 1.6481\n",
            "Epoch 2/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.7970 - val_loss: 1.4635\n",
            "Epoch 3/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.7085 - val_loss: 1.3588\n",
            "Epoch 4/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.6485 - val_loss: 1.2573\n",
            "Epoch 5/100\n",
            "112000/112000 [==============================] - 105s 935us/step - loss: 0.6058 - val_loss: 1.2031\n",
            "Epoch 6/100\n",
            "112000/112000 [==============================] - 104s 933us/step - loss: 0.5742 - val_loss: 1.1930\n",
            "Epoch 7/100\n",
            "112000/112000 [==============================] - 104s 933us/step - loss: 0.5501 - val_loss: 1.1337\n",
            "Epoch 8/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.5314 - val_loss: 1.1054\n",
            "Epoch 9/100\n",
            "112000/112000 [==============================] - 104s 928us/step - loss: 0.5162 - val_loss: 1.0712\n",
            "Epoch 10/100\n",
            "112000/112000 [==============================] - 103s 923us/step - loss: 0.5032 - val_loss: 1.1108\n",
            "Epoch 11/100\n",
            "112000/112000 [==============================] - 103s 920us/step - loss: 0.4901 - val_loss: 1.0486\n",
            "Epoch 12/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.4797 - val_loss: 1.0535\n",
            "Epoch 13/100\n",
            "112000/112000 [==============================] - 104s 925us/step - loss: 0.4715 - val_loss: 1.0143\n",
            "Epoch 14/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.4641 - val_loss: 1.0447\n",
            "Epoch 15/100\n",
            "112000/112000 [==============================] - 104s 930us/step - loss: 0.4578 - val_loss: 0.9911\n",
            "Epoch 16/100\n",
            "112000/112000 [==============================] - 104s 928us/step - loss: 0.4521 - val_loss: 1.0383\n",
            "Epoch 17/100\n",
            "112000/112000 [==============================] - 104s 927us/step - loss: 0.4469 - val_loss: 1.0187\n",
            "Epoch 18/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.4398 - val_loss: 1.0039\n",
            "Epoch 19/100\n",
            "112000/112000 [==============================] - 104s 927us/step - loss: 0.4272 - val_loss: 1.0172\n",
            "Epoch 20/100\n",
            "112000/112000 [==============================] - 104s 927us/step - loss: 0.4199 - val_loss: 0.9874\n",
            "Epoch 21/100\n",
            "112000/112000 [==============================] - 104s 925us/step - loss: 0.4135 - val_loss: 1.0325\n",
            "Epoch 22/100\n",
            "112000/112000 [==============================] - 103s 924us/step - loss: 0.4082 - val_loss: 1.0224\n",
            "Epoch 23/100\n",
            "112000/112000 [==============================] - 103s 924us/step - loss: 0.4024 - val_loss: 0.9671\n",
            "Epoch 24/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.3965 - val_loss: 1.0026\n",
            "Epoch 25/100\n",
            "112000/112000 [==============================] - 103s 922us/step - loss: 0.3915 - val_loss: 1.0079\n",
            "Epoch 26/100\n",
            "112000/112000 [==============================] - 104s 929us/step - loss: 0.3868 - val_loss: 0.9675\n",
            "Epoch 27/100\n",
            "112000/112000 [==============================] - 103s 922us/step - loss: 0.3828 - val_loss: 0.9872\n",
            "Epoch 28/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.3788 - val_loss: 0.9753\n",
            "Epoch 29/100\n",
            "112000/112000 [==============================] - 103s 924us/step - loss: 0.3755 - val_loss: 0.9646\n",
            "Epoch 30/100\n",
            "112000/112000 [==============================] - 104s 925us/step - loss: 0.3723 - val_loss: 1.0117\n",
            "Epoch 31/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.3694 - val_loss: 0.9692\n",
            "Epoch 32/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.3666 - val_loss: 0.9554\n",
            "Epoch 33/100\n",
            "112000/112000 [==============================] - 104s 931us/step - loss: 0.3640 - val_loss: 1.0242\n",
            "Epoch 34/100\n",
            "112000/112000 [==============================] - 105s 941us/step - loss: 0.3615 - val_loss: 0.9954\n",
            "Epoch 35/100\n",
            "112000/112000 [==============================] - 105s 940us/step - loss: 0.3590 - val_loss: 0.9918\n",
            "Epoch 36/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3565 - val_loss: 1.0265\n",
            "Epoch 37/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.3541 - val_loss: 0.9966\n",
            "Epoch 38/100\n",
            "112000/112000 [==============================] - 105s 936us/step - loss: 0.3518 - val_loss: 1.0161\n",
            "Epoch 39/100\n",
            "112000/112000 [==============================] - 105s 935us/step - loss: 0.3495 - val_loss: 1.0397\n",
            "Epoch 40/100\n",
            "112000/112000 [==============================] - 105s 935us/step - loss: 0.3474 - val_loss: 0.9932\n",
            "Epoch 41/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.3453 - val_loss: 1.0173\n",
            "Epoch 42/100\n",
            "112000/112000 [==============================] - 105s 934us/step - loss: 0.3433 - val_loss: 1.0302\n",
            "Epoch 43/100\n",
            "112000/112000 [==============================] - 105s 940us/step - loss: 0.3415 - val_loss: 0.9983\n",
            "Epoch 44/100\n",
            "112000/112000 [==============================] - 105s 940us/step - loss: 0.3397 - val_loss: 1.0188\n",
            "Epoch 45/100\n",
            "112000/112000 [==============================] - 105s 936us/step - loss: 0.3379 - val_loss: 1.0308\n",
            "Epoch 46/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.3363 - val_loss: 1.0426\n",
            "Epoch 47/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3346 - val_loss: 1.0456\n",
            "Epoch 48/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.3329 - val_loss: 1.0448\n",
            "Epoch 49/100\n",
            "112000/112000 [==============================] - 106s 943us/step - loss: 0.3312 - val_loss: 1.0355\n",
            "Epoch 50/100\n",
            "112000/112000 [==============================] - 106s 947us/step - loss: 0.3297 - val_loss: 1.0418\n",
            "Epoch 51/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3283 - val_loss: 1.0434\n",
            "Epoch 52/100\n",
            "112000/112000 [==============================] - 106s 945us/step - loss: 0.3269 - val_loss: 1.0397\n",
            "Epoch 53/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.3254 - val_loss: 1.0541\n",
            "Epoch 54/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.3281 - val_loss: 0.9941\n",
            "Epoch 55/100\n",
            "112000/112000 [==============================] - 104s 927us/step - loss: 0.3243 - val_loss: 1.0475\n",
            "Epoch 56/100\n",
            "112000/112000 [==============================] - 104s 928us/step - loss: 0.3228 - val_loss: 1.0236\n",
            "Epoch 57/100\n",
            "112000/112000 [==============================] - 104s 931us/step - loss: 0.3215 - val_loss: 1.0498\n",
            "Epoch 58/100\n",
            "112000/112000 [==============================] - 104s 930us/step - loss: 0.3200 - val_loss: 1.0230\n",
            "Epoch 59/100\n",
            "112000/112000 [==============================] - 104s 926us/step - loss: 0.3187 - val_loss: 1.0470\n",
            "Epoch 60/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.3176 - val_loss: 1.0528\n",
            "Epoch 61/100\n",
            "112000/112000 [==============================] - 105s 937us/step - loss: 0.3163 - val_loss: 1.0400\n",
            "Epoch 62/100\n",
            "112000/112000 [==============================] - 106s 944us/step - loss: 0.3152 - val_loss: 1.0744\n",
            "Epoch 63/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3140 - val_loss: 1.0725\n",
            "Epoch 64/100\n",
            "112000/112000 [==============================] - 106s 944us/step - loss: 0.3130 - val_loss: 1.0735\n",
            "Epoch 65/100\n",
            "112000/112000 [==============================] - 106s 944us/step - loss: 0.3121 - val_loss: 1.1095\n",
            "Epoch 66/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3112 - val_loss: 1.0576\n",
            "Epoch 67/100\n",
            "112000/112000 [==============================] - 105s 935us/step - loss: 0.3101 - val_loss: 1.0692\n",
            "Epoch 68/100\n",
            "112000/112000 [==============================] - 105s 936us/step - loss: 0.3091 - val_loss: 1.0998\n",
            "Epoch 69/100\n",
            "112000/112000 [==============================] - 105s 934us/step - loss: 0.3079 - val_loss: 1.0743\n",
            "Epoch 70/100\n",
            "112000/112000 [==============================] - 105s 937us/step - loss: 0.3070 - val_loss: 1.0902\n",
            "Epoch 71/100\n",
            "112000/112000 [==============================] - 105s 934us/step - loss: 0.3063 - val_loss: 1.0710\n",
            "Epoch 72/100\n",
            "112000/112000 [==============================] - 104s 932us/step - loss: 0.3052 - val_loss: 1.1151\n",
            "Epoch 73/100\n",
            "112000/112000 [==============================] - 105s 941us/step - loss: 0.3043 - val_loss: 1.0739\n",
            "Epoch 74/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.3035 - val_loss: 1.0903\n",
            "Epoch 75/100\n",
            "112000/112000 [==============================] - 105s 934us/step - loss: 0.3030 - val_loss: 1.1322\n",
            "Epoch 76/100\n",
            "112000/112000 [==============================] - 105s 936us/step - loss: 0.3020 - val_loss: 1.1044\n",
            "Epoch 77/100\n",
            "112000/112000 [==============================] - 106s 948us/step - loss: 0.3010 - val_loss: 1.1518\n",
            "Epoch 78/100\n",
            "112000/112000 [==============================] - 106s 947us/step - loss: 0.3002 - val_loss: 1.1017\n",
            "Epoch 79/100\n",
            "112000/112000 [==============================] - 104s 931us/step - loss: 0.2995 - val_loss: 1.0959\n",
            "Epoch 80/100\n",
            "112000/112000 [==============================] - 106s 943us/step - loss: 0.2987 - val_loss: 1.1046\n",
            "Epoch 81/100\n",
            "112000/112000 [==============================] - 106s 945us/step - loss: 0.3224 - val_loss: 0.9875\n",
            "Epoch 82/100\n",
            "112000/112000 [==============================] - 106s 947us/step - loss: 0.3043 - val_loss: 1.0617\n",
            "Epoch 83/100\n",
            "112000/112000 [==============================] - 106s 951us/step - loss: 0.2991 - val_loss: 1.0591\n",
            "Epoch 84/100\n",
            "112000/112000 [==============================] - 106s 948us/step - loss: 0.2977 - val_loss: 1.0953\n",
            "Epoch 85/100\n",
            "112000/112000 [==============================] - 106s 946us/step - loss: 0.2964 - val_loss: 1.0656\n",
            "Epoch 86/100\n",
            "112000/112000 [==============================] - 105s 941us/step - loss: 0.2956 - val_loss: 1.0967\n",
            "Epoch 87/100\n",
            "112000/112000 [==============================] - 106s 948us/step - loss: 0.2946 - val_loss: 1.0818\n",
            "Epoch 88/100\n",
            "112000/112000 [==============================] - 106s 944us/step - loss: 0.2940 - val_loss: 1.0978\n",
            "Epoch 89/100\n",
            "112000/112000 [==============================] - 106s 947us/step - loss: 0.2932 - val_loss: 1.0974\n",
            "Epoch 90/100\n",
            "112000/112000 [==============================] - 106s 946us/step - loss: 0.2924 - val_loss: 1.0963\n",
            "Epoch 91/100\n",
            "112000/112000 [==============================] - 105s 940us/step - loss: 0.2918 - val_loss: 1.1045\n",
            "Epoch 92/100\n",
            "112000/112000 [==============================] - 105s 942us/step - loss: 0.2911 - val_loss: 1.1252\n",
            "Epoch 93/100\n",
            "112000/112000 [==============================] - 106s 942us/step - loss: 0.2903 - val_loss: 1.1448\n",
            "Epoch 94/100\n",
            "112000/112000 [==============================] - 106s 949us/step - loss: 0.2898 - val_loss: 1.1199\n",
            "Epoch 95/100\n",
            "112000/112000 [==============================] - 105s 938us/step - loss: 0.2891 - val_loss: 1.1117\n",
            "Epoch 96/100\n",
            "112000/112000 [==============================] - 105s 935us/step - loss: 0.2885 - val_loss: 1.1192\n",
            "Epoch 97/100\n",
            "112000/112000 [==============================] - 106s 945us/step - loss: 0.2879 - val_loss: 1.1262\n",
            "Epoch 98/100\n",
            "112000/112000 [==============================] - 106s 944us/step - loss: 0.2872 - val_loss: 1.1289\n",
            "Epoch 99/100\n",
            "112000/112000 [==============================] - 106s 947us/step - loss: 0.2866 - val_loss: 1.1192\n",
            "Epoch 100/100\n",
            "112000/112000 [==============================] - 105s 939us/step - loss: 0.2861 - val_loss: 1.1172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f9ac5d9c400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkk7genYTZ5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('neural_machine_translation_french_to_english.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUDpVwkGTaBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipvhrpDnTaJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_char_to_idx['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "    \n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = target_idx_to_char[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "              stop_condition = True\n",
        "      \n",
        "\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "        states_value = [h, c]\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCrEmZpfTaHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(seq_index):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_dataset[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MSW0zkCTaAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5d07db73-b88d-447a-b08a-7c7144b271fd"
      },
      "source": [
        "decode(14441)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: essayez de ne pas rire\n",
            "Decoded sentence: try to relax anything\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn6WzE-STZ-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d34f46f5-1875-4313-d3a4-373510bd8cd7"
      },
      "source": [
        "decode(12345)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: ton chien est la\n",
            "Decoded sentence: your father is in the room\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}